{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9006666666666666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "class MultinomialNaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.class_probs = {}\n",
    "        self.feature_probs = {}\n",
    "\n",
    "        # Calculate class probabilities\n",
    "        for cls in self.classes:\n",
    "            # Calculate prior probability of each class\n",
    "            self.class_probs[cls] = np.sum(y == cls) / len(y)\n",
    "\n",
    "            # Extract data for the current class\n",
    "            X_cls = X[y == cls]\n",
    "            \n",
    "            # Calculate feature probabilities for each class\n",
    "            self.feature_probs[cls] = {}\n",
    "            for feature in range(X.shape[1]):\n",
    "                feature_values = X_cls[:, feature]\n",
    "                total_count = np.sum(feature_values)\n",
    "                self.feature_probs[cls][feature] = {\n",
    "                    'prob': (feature_values.sum() + 1) / (total_count + len(np.unique(X[:, feature]))),\n",
    "                    'count': total_count\n",
    "                }\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for instance in X:\n",
    "            max_prob = -1\n",
    "            prediction = None\n",
    "            for cls in self.classes:\n",
    "                prob = np.log(self.class_probs[cls])\n",
    "                for feature, value in enumerate(instance):\n",
    "                    if value > 0:  # Considering only non-zero features\n",
    "                        prob += np.log(self.feature_probs[cls][feature]['prob'])\n",
    "\n",
    "                if prob > max_prob or max_prob == -1:\n",
    "                    max_prob = prob\n",
    "                    prediction = cls\n",
    "\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('./diabetes_prediction_dataset.csv')\n",
    "# np.random.shuffle(data)\n",
    "data = pd.get_dummies(data, columns=['gender','smoking_history'])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('diabetes', axis=1)  # Features\n",
    "y = data['diabetes']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize Gaussian Naïve Bayes classifier\n",
    "gnb = MultinomialNB()\n",
    "\n",
    "# Train the classifier using the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Female</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0      Female  80.0             0              1           never  25.19   \n",
       "1      Female  54.0             0              0         No Info  27.32   \n",
       "2        Male  28.0             0              0           never  27.32   \n",
       "3      Female  36.0             0              0         current  23.45   \n",
       "4        Male  76.0             1              1         current  20.14   \n",
       "...       ...   ...           ...            ...             ...    ...   \n",
       "99995  Female  80.0             0              0         No Info  27.32   \n",
       "99996  Female   2.0             0              0         No Info  17.37   \n",
       "99997    Male  66.0             0              0          former  27.83   \n",
       "99998  Female  24.0             0              0           never  35.42   \n",
       "99999  Female  57.0             0              0         current  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  diabetes  \n",
       "0              6.6                  140         0  \n",
       "1              6.6                   80         0  \n",
       "2              5.7                  158         0  \n",
       "3              5.0                  155         0  \n",
       "4              4.8                  155         0  \n",
       "...            ...                  ...       ...  \n",
       "99995          6.2                   90         0  \n",
       "99996          6.5                  100         0  \n",
       "99997          5.7                  155         0  \n",
       "99998          4.0                  100         0  \n",
       "99999          6.6                   90         0  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rushi\\AppData\\Local\\Temp\\ipykernel_96312\\810372434.py:67: RuntimeWarning: Mean of empty slice\n",
      "  means = np.nanmean(X_train, axis=0)\n",
      "c:\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:245: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(dtype, copy=copy, casting=casting)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y_true contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rushi\\Downloads\\CS613\\final Project\\code.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rushi/Downloads/CS613/final%20Project/code.ipynb#W2sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m X_valid_bin \u001b[39m=\u001b[39m (X_valid \u001b[39m>\u001b[39m means)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rushi/Downloads/CS613/final%20Project/code.ipynb#W2sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m Y_valid_pred \u001b[39m=\u001b[39m nb_class(X_train_bin, Y_train\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m), X_valid_bin)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rushi/Downloads/CS613/final%20Project/code.ipynb#W2sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m accuracy, confusion \u001b[39m=\u001b[39m evaluate(Y_valid, Y_valid_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rushi/Downloads/CS613/final%20Project/code.ipynb#W2sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation Accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rushi/Downloads/CS613/final%20Project/code.ipynb#W2sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mConfusion Matrix:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\rushi\\Downloads\\CS613\\final Project\\code.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rushi/Downloads/CS613/final%20Project/code.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m num_correct \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mlen\u001b[39m(actual_lab)) \u001b[39m*\u001b[39m \u001b[39m100.0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rushi/Downloads/CS613/final%20Project/code.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m acc \u001b[39m=\u001b[39m comp_acc(true_lab, pred_lab)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rushi/Downloads/CS613/final%20Project/code.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m conf_matrix \u001b[39m=\u001b[39m confusion_matrix(true_lab, pred_lab)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rushi/Downloads/CS613/final%20Project/code.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mreturn\u001b[39;00m acc, conf_matrix\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m    232\u001b[0m     {\n\u001b[0;32m    233\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m ):\n\u001b[0;32m    244\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    327\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    328\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[39mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m---> 85\u001b[0m type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_true\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     86\u001b[0m type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m y_type \u001b[39m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:383\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    381\u001b[0m     data \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m issparse(y) \u001b[39melse\u001b[39;00m y\n\u001b[0;32m    382\u001b[0m     \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39many(data \u001b[39m!=\u001b[39m xp\u001b[39m.\u001b[39mastype(data, \u001b[39mint\u001b[39m)):\n\u001b[1;32m--> 383\u001b[0m         _assert_all_finite(data, input_name\u001b[39m=\u001b[39;49minput_name)\n\u001b[0;32m    384\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[0;32m    386\u001b[0m \u001b[39m# Check multiclass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    123\u001b[0m     X,\n\u001b[0;32m    124\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[0;32m    125\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[0;32m    126\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[0;32m    127\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    128\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    129\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y_true contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def nb_class(train_feat, train_lab, val_feat):\n",
    "    n_train_samples, n_feat = train_feat.shape\n",
    "    n_classes = len(np.unique(train_lab))\n",
    "    class_pr = {}\n",
    "    naive_probs = {}\n",
    "\n",
    "    # Calculate class probabilities\n",
    "    for cl_lab in range(n_classes):\n",
    "        samples_cl = train_feat[train_lab == cl_lab]\n",
    "        class_pr[cl_lab] = len(samples_cl) / n_train_samples\n",
    "\n",
    "        naive_probs[cl_lab] = {}\n",
    "        for feat_idx in range(n_feat):\n",
    "            feat_values = samples_cl[:, feat_idx]\n",
    "            unique_vals, counts = np.unique(feat_values, return_counts=True)\n",
    "            total_vals = len(feat_values)\n",
    "            probs = (counts + 1) / (total_vals + len(unique_vals))\n",
    "            naive_probs[cl_lab][feat_idx] = dict(zip(unique_vals, probs))\n",
    "\n",
    "    predictions = []\n",
    "    # Make predictions for each sample in the validation set\n",
    "    for sample in val_feat:\n",
    "        class_scores = []\n",
    "        for cl_lab in range(n_classes):\n",
    "            log_likelihood = np.sum([np.log(naive_probs[cl_lab][feat].get(value, 1e-10))\n",
    "                                     for feat, value in enumerate(sample)])\n",
    "            class_scores.append(np.log(class_pr[cl_lab]) + log_likelihood)\n",
    "\n",
    "        # Choose the class with the highest score as the predicted class\n",
    "        predictions.append(np.argmax(class_scores))\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "def evaluate(true_lab, pred_lab):\n",
    "    def comp_acc(actual_lab, pred_lab):\n",
    "        num_correct = sum(1 for i in range(len(actual_lab)) if actual_lab[i] == pred_lab[i])\n",
    "        return num_correct / float(len(actual_lab)) * 100.0\n",
    "\n",
    "    acc = comp_acc(true_lab, pred_lab)\n",
    "    conf_matrix = confusion_matrix(true_lab, pred_lab)\n",
    "    \n",
    "    return acc, conf_matrix\n",
    "\n",
    "\n",
    "data = np.genfromtxt('./diabetes_prediction_dataset.csv', delimiter=',')\n",
    "np.random.seed(13)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "n_samples = len(data)\n",
    "train_size = int(np.ceil(2/3 * n_samples))\n",
    "\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size:]\n",
    "\n",
    "X_train = train_data[:, :-2]\n",
    "Y_train = train_data[:, -1]\n",
    "X_valid = val_data[:, :-2]\n",
    "Y_valid = val_data[:, -1]\n",
    "\n",
    "means = np.nanmean(X_train, axis=0)\n",
    "X_train_bin = (X_train > means).astype(int)\n",
    "X_valid_bin = (X_valid > means).astype(int)\n",
    "\n",
    "Y_valid_pred = nb_class(X_train_bin, Y_train.astype(int), X_valid_bin)\n",
    "\n",
    "accuracy, confusion = evaluate(Y_valid, Y_valid_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " -2147483648       1.00      0.00      0.00         1\n",
      "           0       0.94      0.97      0.95     30455\n",
      "           1       0.45      0.29      0.36      2877\n",
      "\n",
      "    accuracy                           0.91     33333\n",
      "   macro avg       0.80      0.42      0.44     33333\n",
      "weighted avg       0.89      0.91      0.90     33333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_valid, Y_valid_pred,zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     1     0]\n",
      " [    0 29443  1012]\n",
      " [    0  2037   840]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_valid, Y_valid_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes\n",
       "0    91500\n",
       "1     8500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./diabetes_prediction_dataset.csv')\n",
    "data['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0             30455\n",
       " 1              2877\n",
       "-2147483648        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Y_valid).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
